{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "# Configuramos el uso de TkAgg como backend para matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función personalizada para mostrar imágenes\n",
    "def imshow(\n",
    "    img,\n",
    "    new_fig=True,\n",
    "    title=None,\n",
    "    color_img=False,\n",
    "    blocking=False,\n",
    "    colorbar=False,\n",
    "    ticks=False,\n",
    "):\n",
    "    # Si new_fig es True, crea una nueva figura\n",
    "    if new_fig:\n",
    "        plt.figure()\n",
    "    # Si color_img es True, muestra la imagen en su color original\n",
    "    if color_img:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        # Si no, muestra la imagen en escala de grises\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "    # Agregar título a la imagen\n",
    "    plt.title(title)\n",
    "    # Si no se desea mostrar los ticks, se eliminan\n",
    "    if not ticks:\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "    # Si se pide, añadir una barra de colores\n",
    "    if colorbar:\n",
    "        plt.colorbar()\n",
    "    # Mostrar la imagen con la opción de bloqueo si es necesario\n",
    "    if new_fig:\n",
    "        plt.show(block=blocking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar la reconstrucción morfológica de una imagen\n",
    "def imreconstruct(marker, mask, kernel=None):\n",
    "    # Asegurarse de que 'marker' y 'mask' tengan el mismo tamaño y tipo\n",
    "    if marker.shape != mask.shape:\n",
    "        raise ValueError(\"El tamaño de 'marker' y 'mask' debe ser igual\")\n",
    "    if marker.dtype != mask.dtype:\n",
    "        marker = marker.astype(mask.dtype)\n",
    "\n",
    "    # Si no se proporciona un kernel, utilizar uno por defecto (3x3)\n",
    "    if kernel is None:\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    while True:\n",
    "        # Dilatación del marcador\n",
    "        expanded = cv2.dilate(marker, kernel)\n",
    "\n",
    "        # Realizar una intersección entre la imagen dilatada y la máscara\n",
    "        expanded_intersection = cv2.bitwise_and(expanded, mask)\n",
    "\n",
    "        # Verificar si la reconstrucción ha convergido (si no hay cambios)\n",
    "        if np.array_equal(marker, expanded_intersection):\n",
    "            break\n",
    "\n",
    "        # Actualizar el marcador para la siguiente iteración\n",
    "        marker = expanded_intersection\n",
    "\n",
    "    return expanded_intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función imreconstruct implementa el algoritmo de reconstrucción morfológica para imágenes. Este proceso es fundamental en la segmentación y el análisis de imágenes, permitiendo extraer o restaurar estructuras específicas dentro de una imagen. En términos generales, la reconstrucción morfológica se utiliza para propagar las regiones definidas en una imagen inicial (marcador) dentro de los límites impuestos por otra imagen (máscara).\n",
    "\n",
    "- Entrada:\n",
    "\n",
    "    - marker: Imagen inicial que define las regiones de inicio.\n",
    "    - mask: Imagen que establece los límites de propagación.\n",
    "    - kernel (opcional): Estructura que define la vecindad para la operación de dilatación.\n",
    "\n",
    "- Salida:\n",
    "    - Imagen reconstruida, donde las regiones del marcador se expanden dentro de los límites de la máscara según las operaciones morfológicas.\n",
    "\n",
    "El algoritmo itera aplicando dilataciones sobre la imagen marcador, seguida de una intersección con la máscara, hasta alcanzar un estado de convergencia donde no se producen cambios.\n",
    "\n",
    "La lógica iterativa garantiza que el proceso de reconstrucción sea robusto y adaptable a imágenes de diferentes tipos y resoluciones. Además, incluir el parámetro opcional kernel proporciona flexibilidad para abordar tareas específicas de procesamiento, desde ajustes finos en microestructuras hasta operaciones en imágenes más grandes.\n",
    "\n",
    "- Precisión en la segmentación: Este método permite una segmentación más precisa, ya que las regiones se expanden controladamente dentro de los límites definidos por la máscara.\n",
    "- Control personalizado: La función admite un kernel configurable, lo que permite adaptar el proceso a diferentes requisitos de vecindad en imágenes.\n",
    "- Versatilidad: Puede usarse en múltiples aplicaciones como:\n",
    "    - Eliminación de ruido.\n",
    "    - Restauración de objetos conectados.\n",
    "    - Mejoramiento de bordes o formas específicas.\n",
    "- Optimización iterativa: La reconstrucción converge automáticamente cuando no hay cambios en la imagen, evitando iteraciones innecesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para rellenar huecos en una imagen binaria\n",
    "def imfillhole(img):\n",
    "    # Crear una máscara de ceros para los bordes de la imagen\n",
    "    mask = np.zeros_like(img)\n",
    "    # Generar bordes alrededor de la máscara para realizar la operación de dilatación\n",
    "    mask = cv2.copyMakeBorder(\n",
    "        mask[1:-1, 1:-1], 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=int(255)\n",
    "    )\n",
    "    # El marcador es el complemento de los bordes\n",
    "    marker = cv2.bitwise_not(img, mask=mask)\n",
    "    # La máscara es el complemento de la imagen original\n",
    "    img_c = cv2.bitwise_not(img)\n",
    "    # Realizar la reconstrucción morfológica\n",
    "    img_r = imreconstruct(marker=marker, mask=img_c)\n",
    "    # La imagen con los huecos rellenos es el complemento de la reconstrucción\n",
    "    img_fh = cv2.bitwise_not(img_r)\n",
    "    return img_fh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función imfillhole se encarga de rellenar huecos en una imagen binaria, un proceso crucial en el análisis de imágenes para asegurar la continuidad de objetos o regiones. Los huecos se definen como áreas negras rodeadas por regiones blancas en una imagen binaria. Este método garantiza que dichas áreas sean identificadas y completadas adecuadamente.\n",
    "\n",
    "- Entrada:\n",
    "\n",
    "    - img: Imagen binaria en la que se desea rellenar los huecos.\n",
    "- Salida:\n",
    "\n",
    "    - Imagen binaria procesada donde los huecos han sido rellenados.\n",
    "\n",
    "El método aprovecha la reconstrucción morfológica para identificar y completar los huecos:\n",
    "\n",
    "- Se genera una máscara a partir del borde exterior de la imagen.\n",
    "- El marcador inicial se construye como el complemento de la imagen dentro de la máscara.\n",
    "- La reconstrucción morfológica propaga las regiones a partir del marcador, limitándose por la máscara.\n",
    "- Finalmente, se devuelve el complemento de la imagen reconstruida para obtener la imagen final con los huecos rellenados.\n",
    "\n",
    "Además, al estar basada en la función imreconstruct, tu código aprovecha la flexibilidad y modularidad de esta implementación, permitiendo una integración fluida con otros pasos del pipeline de procesamiento. Esto hace que sea un enfoque eficiente y personalizable para tareas complejas.\n",
    "\n",
    "Esta función es esencial en contextos donde los objetos deben representarse como regiones completas sin interrupciones. Ejemplos prácticos incluyen:\n",
    "\n",
    "- Preparación para segmentación: Asegura que los objetos estén completamente conectados antes de aplicar algoritmos de segmentación o clasificación.\n",
    "- Post-procesamiento en visión computacional: Mejora la calidad de las imágenes binarizadas para análisis como reconocimiento de formas o mediciones precisas.\n",
    "- Eliminación de imperfecciones: Rellena artefactos no deseados que aparecen como huecos debido a ruido o fallos en etapas previas de procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para encontrar el menor factor de forma\n",
    "def menor_factor_de_forma(factor):\n",
    "    primero = 1  # Valor inicial más grande para el factor de forma\n",
    "    indiceuno = 0\n",
    "    for registro in factor:\n",
    "        if registro[1] < primero:  # Si encontramos un valor más pequeño\n",
    "            primero = registro[1]\n",
    "            indiceuno = registro[0]\n",
    "    factor.pop(indiceuno - 1)  # Eliminar el elemento con el factor más pequeño\n",
    "    return indiceuno, primero, factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionalidad\n",
    "La función menor_factor_de_forma identifica el menor factor de forma dentro de una lista de registros y devuelve la información asociada al mismo. Esta operación es útil en análisis donde es necesario priorizar elementos con características mínimas específicas, como en análisis de formas o geometría de objetos.\n",
    "\n",
    "- Entrada:\n",
    "\n",
    "    - factor: Lista de tuplas o listas, donde cada elemento contiene un índice y un valor asociado al factor de forma. Ejemplo: [(1, 0.8), (2, 0.5), (3, 0.9)].\n",
    "- Salida:\n",
    "\n",
    "    - Índice (indiceuno) correspondiente al menor factor de forma.\n",
    "    - Valor del menor factor de forma (primero).\n",
    "    - Lista actualizada con el elemento correspondiente eliminado.\n",
    "El algoritmo recorre la lista buscando el menor valor en la segunda posición de cada registro y elimina ese elemento de la lista original, devolviendo la información necesaria.\n",
    "\n",
    "Ventajas\n",
    "- Simplicidad y claridad: La función es directa en su propósito, lo que facilita su comprensión e integración en pipelines más complejos.\n",
    "- Optimización del análisis: Identifica y elimina el menor factor en una sola pasada, reduciendo la necesidad de operaciones redundantes.\n",
    "- Versatilidad: Puede adaptarse para trabajar con diferentes métricas, no solo factores de forma, ampliando su aplicabilidad.\n",
    "- Estructura ordenada: Devuelve los resultados de forma estructurada, permitiendo un uso inmediato en cálculos posteriores.\n",
    "\n",
    "\n",
    "Justificación de Uso\n",
    "Este enfoque es ideal para escenarios donde es necesario iterar sobre una lista priorizando elementos según un criterio de minimización, como:\n",
    "\n",
    "- Selección óptima en análisis geométrico: Identificar objetos con características específicas (menor asimetría, menor compactación, etc.).\n",
    "- Procesamiento iterativo en clustering: Reducir iterativamente una lista de candidatos con el menor costo o factor asociado.\n",
    "- Sistemas de optimización y clasificación: Usar el menor valor como pivote para decisiones posteriores.\n",
    "- La eliminación directa del menor factor asegura que la lista se reduce dinámicamente, simplificando iteraciones futuras y mejorando la eficiencia computacional.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para encontrar el área más pequeña en una lista de monedas\n",
    "def menor_area(monedas):\n",
    "    area_chica = 100000000  # Valor inicial muy grande para el área\n",
    "    for i in range(len(monedas)):\n",
    "        if monedas[i][1] < area_chica:  # Si encontramos un área más pequeña\n",
    "            area_chica = monedas[i][1]\n",
    "            indice = i\n",
    "    return indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionalidad\n",
    "La función menor_area busca encontrar el índice de la moneda con el área más pequeña dentro de una lista. Este tipo de análisis es común en procesamiento de imágenes y visión por computadora, especialmente cuando se trabaja con objetos detectados o segmentados, como monedas, partículas, o regiones de interés.\n",
    "\n",
    "- Entrada:\n",
    "\n",
    "    - monedas: Lista donde cada elemento representa una moneda. Se espera que cada elemento sea una tupla o lista con al menos dos valores:\n",
    "        - Identificador o índice de la moneda.\n",
    "        - Área de la moneda.\n",
    "- Salida:\n",
    "\n",
    "    - indice: Índice de la moneda con el área más pequeña.\n",
    "\n",
    "\n",
    "El algoritmo recorre toda la lista y compara cada área con un valor inicial muy grande (area_chica). Si encuentra un área menor, actualiza tanto el valor del área mínima como el índice correspondiente. Finalmente, devuelve el índice del elemento con el área más pequeña.\n",
    "\n",
    "Ventajas\n",
    "- Simplicidad en el diseño: La función es fácil de entender y directa en su propósito, ideal para integrarse en sistemas de procesamiento más complejos.\n",
    "- Aplicación específica: Es útil para análisis donde se necesita priorizar elementos pequeños, como:\n",
    "    - Eliminación de artefactos o ruido basado en tamaño.\n",
    "    - Identificación de la moneda más pequeña en una imagen para tareas de clasificación o comparación.\n",
    "- Eficiencia lineal: El recorrido de la lista tiene complejidad 𝑂(𝑛). lo que es eficiente para listas de tamaño moderado.\n",
    "\n",
    "\n",
    "Justificación de Uso\n",
    "Esta función puede justificarse en el contexto de procesamiento de imágenes como una herramienta clave para análisis de objetos detectados, como monedas u otras formas similares. Algunas aplicaciones prácticas incluyen:\n",
    "\n",
    "- Clasificación de objetos según tamaño: Identificar el objeto más pequeño como parte de un proceso de etiquetado o caracterización.\n",
    "- Filtrado por área mínima: Ayudar a eliminar regiones no deseadas en imágenes segmentadas, como artefactos o ruido.\n",
    "- Optimización en sistemas de conteo: Localizar elementos pequeños puede ser crucial en sistemas que evalúan la calidad o clasifican objetos.\n",
    "\n",
    "\n",
    "El uso de un valor inicial alto garantiza que cualquier área de la lista será seleccionada, incluso en caso de valores extremadamente pequeños. Esto hace que la función sea robusta para trabajar con datos variados y asegura que siempre haya un resultado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer la imagen de monedas\n",
    "moneda = cv2.imread(\"monedas.jpg\", cv2.IMREAD_COLOR)\n",
    "# Convertir la imagen de BGR a RGB\n",
    "moneda_original = cv2.cvtColor(moneda, cv2.COLOR_BGR2RGB)\n",
    "# Convertir la imagen a escala de grises\n",
    "img_fil_gray = cv2.cvtColor(moneda_original, cv2.COLOR_RGB2GRAY)\n",
    "# Aplicar un filtro gaussiano para suavizar la imagen\n",
    "filtrado = cv2.GaussianBlur(img_fil_gray, (5, 5), 0)\n",
    "# Detectar bordes utilizando el algoritmo de Canny\n",
    "canny = cv2.Canny(filtrado, 75, 150)\n",
    "# Aplicar dilatación a la imagen de bordes para agrandar los objetos\n",
    "dilatacion = cv2.dilate(canny, np.ones((13, 13), np.uint8))\n",
    "# Realizar una operación de cierre morfológico para rellenar huecos\n",
    "img_modif = cv2.morphologyEx(dilatacion, cv2.MORPH_CLOSE, np.ones((27, 27), np.uint8))\n",
    "\n",
    "\n",
    "imshow(dilatacion, title=\"Original\")  # Descomentar si deseas ver la dilatación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionalidad\n",
    "Este código realiza un preprocesamiento sobre una imagen de monedas para preparar los datos y facilitar su análisis posterior. El flujo de trabajo incluye pasos clave como la conversión de color, filtrado, detección de bordes y operaciones morfológicas. El objetivo es realzar las características relevantes de las monedas, asegurando una segmentación más precisa.\n",
    "\n",
    "- Lectura y conversión de la imagen:\n",
    "\n",
    "    - Se carga la imagen monedas.jpg en color y se convierte a RGB para estandarizar su formato.\n",
    "    - Luego, se convierte a escala de grises (GRAY) para simplificar las operaciones posteriores.\n",
    "- Filtrado y detección de bordes:\n",
    "\n",
    "    - Se aplica un filtro gaussiano para suavizar la imagen y reducir el ruido, lo que mejora la detección de bordes.\n",
    "    - Con el algoritmo de Canny, se detectan los bordes principales de los objetos (monedas) en la imagen.\n",
    "- Operaciones morfológicas:\n",
    "\n",
    "    - La dilatación expande los bordes detectados, asegurando que las monedas tengan contornos más definidos.\n",
    "    - El cierre morfológico rellena huecos dentro de los objetos, convirtiendo bordes incompletos en regiones sólidas y conectadas.\n",
    "- Visualización:\n",
    "    - la línea imshow permite visualizar la imagen dilatada para inspeccionar los resultados intermedios.\n",
    "\n",
    "Ventajas\n",
    "- Preparación robusta de datos: Este pipeline combina técnicas que aseguran que las monedas estén bien definidas y listas para el análisis posterior.\n",
    "- Reducción de ruido: El filtro gaussiano y las operaciones morfológicas mitigan los efectos del ruido, mejorando la precisión de detección.\n",
    "- Generalización: El enfoque es adaptable a imágenes con diferentes condiciones de iluminación o resolución.\n",
    "- Modularidad: Cada paso del flujo de trabajo es independiente, lo que facilita ajustes específicos según los requisitos de la tarea.\n",
    "\n",
    "Justificación de Uso\n",
    "El preprocesamiento es un paso esencial en cualquier pipeline de procesamiento de imágenes. En este caso:\n",
    "\n",
    "- Filtrado y detección precisa: La combinación de filtrado gaussiano y Canny asegura que solo se detecten bordes relevantes, reduciendo artefactos o detalles irrelevantes.\n",
    "- Mejoramiento de contornos: La dilatación y el cierre garantizan que las monedas sean tratadas como regiones completas, lo que facilita análisis como el cálculo de áreas o identificación de factores de forma.\n",
    "- Estandarización para segmentación: La imagen procesada tiene características uniformes que permiten una segmentación y análisis consistente, incluso en conjuntos de datos variados.\n",
    "- Este pipeline es ideal para proyectos donde el objetivo es extraer información de objetos circulares o aislados en una imagen, como la identificación de monedas, partículas o células."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llenar los huecos en la imagen de las monedas\n",
    "relleno = imfillhole(img_modif)\n",
    "\n",
    "imshow(relleno, title=\"Moneda Rellenada\")  # Descomentar si deseas ver la imagen rellena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar una operación de erosión a la imagen de las monedas rellenas\n",
    "erocion = cv2.erode(relleno, np.ones((41, 41), np.uint8))\n",
    "\n",
    "imshow(erocion, title=\"Monedas Erocionadas\")  # Descomentar si deseas ver la erosión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar las listas para el factor de forma y las cajas\n",
    "factordeforma = []\n",
    "caja = []\n",
    "# Obtener los componentes conectados en la imagen de las monedas erosionadas\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(erocion)\n",
    "for i_label in range(1, num_labels):\n",
    "    area = stats[i_label, cv2.CC_STAT_AREA]\n",
    "    filtered_labels = np.zeros_like(erocion, dtype=np.uint8)\n",
    "    filtered_labels[labels == i_label] = 255\n",
    "    # Encontrar los contornos de los componentes\n",
    "    contours, _ = cv2.findContours(\n",
    "        filtered_labels, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE\n",
    "    )\n",
    "    for contour in contours:\n",
    "        # Calcular el bounding box (caja delimitadora)\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        perimetro = cv2.arcLength(contour, True)  # Perímetro del contorno\n",
    "        factor_forma = area / (perimetro**2)  # Calcular el factor de forma\n",
    "        factordeforma.append([i_label, factor_forma])  # Guardar factor de forma\n",
    "        caja.append([i_label, area, x, y, w, h])  # Guardar información de la caja\n",
    "\n",
    "# Encontrar el menor factor de forma (más pequeño)\n",
    "indice, factor, factordeforma2 = menor_factor_de_forma(factordeforma)\n",
    "indice2, factor2, factordeforma3 = menor_factor_de_forma(factordeforma2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionalidad\n",
    "Este segmento de código realiza la análisis de componentes conectados en la imagen procesada para identificar y analizar objetos individuales (en este caso, monedas). Posteriormente, calcula métricas geométricas como el factor de forma y extrae las cajas delimitadoras de cada objeto.\n",
    "\n",
    "- Inicialización de listas:\n",
    "\n",
    "    - factordeforma: Almacena el índice del componente conectado y su respectivo factor de forma.\n",
    "    - caja: Almacena información geométrica clave para cada objeto (área y bounding box).\n",
    "- Detección de componentes conectados:\n",
    "\n",
    "    - cv2.connectedComponentsWithStats: Identifica regiones conectadas (objetos) en la imagen erosionada (erocion) y devuelve:\n",
    "    - num_labels: Cantidad de componentes detectados.\n",
    "    - labels: Imagen etiquetada donde cada píxel pertenece a un componente.\n",
    "    - stats: Métricas estadísticas de cada componente (como área, bounding box, etc.).\n",
    "    - centroids: Coordenadas de los centroides de cada componente.\n",
    "- Análisis por componente: Para cada componente identificado:\n",
    "\n",
    "- Se calcula el área y se crea una máscara binaria específica para ese componente.\n",
    "- Se encuentran los contornos del objeto dentro de la máscara (cv2.findContours).\n",
    "- Se calcula:\n",
    "    - Bounding box (x, y, w, h): Define el rectángulo mínimo que contiene el objeto.\n",
    "    - Perímetro (cv2.arcLength): Longitud del contorno.\n",
    "    - Factor de forma: Relación entre el área y el cuadrado del perímetro, utilizada como métrica de compactación o regularidad.\n",
    "    - Estos valores se almacenan en las listas factordeforma y caja.\n",
    "\n",
    "- Identificación de factores de forma mínimos:\n",
    "\n",
    "    - Se utiliza la función menor_factor_de_forma para encontrar los componentes con los menores factores de forma.\n",
    "    - Esto ayuda a identificar los objetos menos compactos o con mayor irregularidad.\n",
    "\n",
    "Ventajas\n",
    "- Análisis completo: Combina la detección de componentes conectados con métricas geométricas avanzadas.\n",
    "- Automatización: Permite calcular automáticamente el factor de forma y extraer bounding boxes para múltiples objetos.\n",
    "- Flexibilidad: El enfoque es modular y puede adaptarse a diferentes tipos de imágenes y métricas.\n",
    "- Identificación de características clave: La métrica de factor de forma es útil para priorizar objetos según su geometría (como círculos, elipses o formas más complejas).\n",
    "\n",
    "Justificación de Uso\n",
    "Este enfoque es crucial en contextos donde se deben analizar múltiples objetos segmentados en una imagen. En el caso específico de monedas:\n",
    "\n",
    "- Caracterización geométrica: El factor de forma ayuda a distinguir entre monedas regulares (compactas) y artefactos o ruido (menos compactos).\n",
    "- Detección y extracción de regiones: Las cajas delimitadoras permiten aislar monedas individuales para análisis o procesamiento adicional.\n",
    "- Filtrado basado en propiedades: Identificar los factores de forma más bajos permite enfocar el análisis en los objetos más irregulares, lo cual es útil para detectar anomalías.\n",
    "\n",
    "La combinación de componentes conectados, contornos y bounding boxes proporciona una solución robusta para análisis geométricos en imágenes complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, el factor de forma se refiere a una métrica utilizada para evaluar la \"compactitud\" o la eficiencia geométrica de una figura, como una moneda o un dado. Es una relación entre el área de la figura y su perímetro\n",
    "\n",
    "El factor de forma ayuda a medir cuánto se aleja una figura de una forma ideal (por ejemplo, un círculo para monedas o un cuadrado para dados). Cuanto más cercano sea el factor a 1, más \"compacta\" o similar a una forma geométrica regular es la figura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las monedas con los menores factores de forma\n",
    "monedas = []\n",
    "for i in range(len(factordeforma3)):\n",
    "    for j in range(len(caja)):\n",
    "        if factordeforma3[i][0] == caja[j][0]:\n",
    "            monedas.append(caja[j])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento selecciona las monedas correspondientes a los índices con los menores factores de forma calculados previamente y las almacena en la lista monedas. El propósito es filtrar y priorizar objetos específicos en función de sus características geométricas, como la compactación.\n",
    "\n",
    "- Recorrido de las listas:\n",
    "    - Para cada elemento en factordeforma3 (que contiene los índices y factores de forma más pequeños):\n",
    "        - Se busca un elemento correspondiente en la lista caja (que contiene información completa de cada componente, como área y bounding box).\n",
    "        - Si se encuentra una coincidencia (el índice en ambas listas es igual), se agrega esa caja a la lista monedas.\n",
    "- Almacenamiento en monedas:\n",
    "\n",
    "    - La lista resultante contiene únicamente las cajas delimitadoras y propiedades geométricas de los objetos con menor factor de forma.\n",
    "\n",
    "Este enfoque combina métrica geométrica (factor de forma) con segmentación por componentes conectados, mostrando cómo se pueden aislar objetos relevantes de forma eficiente. Esto evidencia la capacidad de tu código para adaptarse a análisis específicos en conjuntos complejos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las cajas de dados\n",
    "dados = []\n",
    "for i in range(len(caja)):\n",
    "    if caja[i][0] == indice:\n",
    "        dados.append(caja[i])\n",
    "    elif caja[i][0] == indice2:\n",
    "        dados.append(caja[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código selecciona las cajas correspondientes a los índices de los dos objetos con menor factor de forma (ya calculados anteriormente como indice e indice2) y las almacena en la lista dados. El propósito es aislar estos objetos, que podrían representar formas específicas dentro de la imagen (en este caso, podrían ser los \"dados\" u objetos con las características geométricas más inusuales).\n",
    "\n",
    "Funciona de manera similar a Monedas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los umbrales para las monedas\n",
    "umbrales = {\n",
    "    '10 centavos': (0, 50000),\n",
    "    '50 centavos': (70001, 100000),\n",
    "    '1 peso': (50001, 70000)\n",
    "}\n",
    "\n",
    "# Listas iniciales para almacenar monedas etiquetadas\n",
    "monedas_etiqueta = []\n",
    "\n",
    "# Iterar sobre cada moneda\n",
    "for moneda in monedas:\n",
    "    area = moneda[1]  # Segundo elemento: área\n",
    "    etiqueta = 'No definido'\n",
    "    for nombre, (min_area, max_area) in umbrales.items():\n",
    "        if min_area <= area <= max_area:\n",
    "            etiqueta = nombre\n",
    "            break\n",
    "    monedas_etiqueta.append([etiqueta, moneda[2], moneda[3], moneda[4], moneda[5]])\n",
    "\n",
    "# Ordenar las monedas etiquetadas según la categoría\n",
    "monedas_etiqueta = sorted(monedas_etiqueta, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monedas_etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monedas_etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monedas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código selecciona las monedas más pequeñas de una lista específica de objetos (previamente extraída) y las etiqueta según su valor nominal (10 centavos, 1 peso, 50 centavos). Posteriormente, las monedas seleccionadas son almacenadas junto con su información de coordenadas (bounding box) para diferenciarlas según su denominación.\n",
    "\n",
    "- Selección de monedas más pequeñas:\n",
    "\n",
    "    - Se utiliza la función menor_area(monedas) para seleccionar el índice correspondiente a la moneda con el área más pequeña dentro de la lista monedas.\n",
    "        - Esto asegura que solo las monedas más pequeñas sean consideradas.\n",
    "- Etiquetado y agrupamiento:\n",
    "\n",
    "    - Dependiendo del rango de iteración (0-8, 9-13, 14-16), se etiquetan las monedas según su denominación:\n",
    "        - 10 centavos: Para los primeros 9 objetos.\n",
    "        - 1 peso: Para los siguientes 5 objetos (índices 9 a 13).\n",
    "        - 50 centavos: Para los últimos 3 objetos (índices 14 a 16).\n",
    "    Cada moneda seleccionada junto con su información de coordenadas (x, y, w, h) es almacenada en la lista monedas_etiqueta.\n",
    "- Eliminación del objeto procesado:\n",
    "\n",
    "    - Finalmente, la moneda seleccionada (basada en el área mínima) es eliminada de la lista monedas para evitar repetir el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar dilatación y seleccionar los dados\n",
    "delatacion_copia = np.zeros_like(dilatacion, dtype=np.uint8)\n",
    "delatacion_copia[dados[0][3] : dados[0][3] + dados[0][5], dados[0][2] : dados[0][2] + dados[0][4]] = dilatacion[dados[0][3] : dados[0][3] + dados[0][5], dados[0][2] : dados[0][2] + dados[0][4]]\n",
    "delatacion_copia[dados[1][3] - 20 : dados[1][3] + dados[1][5],dados[1][2] : dados[1][2] + dados[1][4],] = dilatacion[dados[1][3] - 20 : dados[1][3] + dados[1][5],dados[1][2] : dados[1][2] + dados[1][4],]\n",
    "\n",
    "imshow(delatacion_copia, title=\"Dados\")  # Descomentar si deseas ver los dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código realiza una dilatación selectiva en la imagen de bordes (dilatacion) para aislar dos dados seleccionados previamente (dados). El objetivo es expandir las áreas de interés (bounding boxes de los dados) para obtener resultados más claros y detallados.\n",
    "\n",
    "- Creación de una copia de la imagen de dilatación:\n",
    "\n",
    "    - delatacion_copia es una máscara inicial que comienza como una imagen en blanco (np.zeros_like) con el mismo tamaño que dilatacion.\n",
    "- Dilatación selectiva:\n",
    "\n",
    "    - La dilatación se realiza solo en las coordenadas correspondientes a los dados seleccionados:\n",
    "        -   Para el primer dado: Se toma un área alrededor de su bounding box (dados[0]), pero con una expansión adicional.\n",
    "        - Para el segundo dado: Se toma su región, aplicando también una expansión de 20 píxeles para cada lado.\n",
    "- Integración de resultados:\n",
    "\n",
    "    - Ambas áreas de dilatación se combinan en delatacion_copia utilizando las coordenadas exactas de los dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erosionar los dados para mejorar la detección\n",
    "erocion_dados = cv2.erode(delatacion_copia, np.ones((11, 11), np.uint8))\n",
    "relleno_dado = imfillhole(erocion_dados)\n",
    "\n",
    "imshow(relleno_dado, title=\"Dados Rellenados\")  # Descomentar si deseas ver los dados rellenados\n",
    "\n",
    "# Erosionar nuevamente\n",
    "erocion_dados2 = cv2.erode(relleno_dado, np.ones((11, 11), np.uint8))\n",
    "\n",
    "imshow(erocion_dados2, title=\"Dados Erocionados\")  # Descomentar si deseas ver los dados erosionados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código realiza operaciones de erosión y relleno de huecos para mejorar la detección y la limpieza de los dados seleccionados previamente. La finalidad es mejorar la precisión en la identificación y separación de objetos tras las operaciones de dilatación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los componentes conectados en la imagen de los dados\n",
    "num_labels_dado, labels_dado, stats_dado, centroids_dado = (\n",
    "    cv2.connectedComponentsWithStats(erocion_dados2)\n",
    ")\n",
    "foto = np.zeros_like(relleno_dado, dtype=np.uint8)\n",
    "for i_label in range(1, num_labels_dado):\n",
    "    area_dado = stats_dado[i_label, cv2.CC_STAT_AREA]\n",
    "    if area_dado > 1000:\n",
    "        foto[labels_dado == i_label] = 255\n",
    "        \n",
    "imshow(foto, title=\"Dados\")  # Descomentar si deseas ver los dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código identifica y procesa los componentes conectados en la imagen después de aplicar la erosión para los dados seleccionados. Los objetos son extraídos y evaluados según su área para clasificar los dados en función de su tamaño.\n",
    "\n",
    "- Componentes conectados:\n",
    "\n",
    "    - cv2.connectedComponentsWithStats(erocion_dados2) calcula los componentes conectados en la imagen erocion_dados2.\n",
    "    - num_labels_dado almacena la cantidad de componentes, labels_dado identifica cada componente, y stats_dado almacena las estadísticas asociadas a cada componente (como área y coordenadas).\n",
    "- Filtrado por área:\n",
    "\n",
    "    - Sólo los componentes cuyo área (area_dado) es mayor que 1000 son considerados. Esto ayuda a excluir componentes no deseados que puedan ser demasiado pequeños o irrelevantes.\n",
    "- Creación de la imagen procesada:\n",
    "\n",
    "    - foto es una imagen en blanco que se llena con 255 en los lugares donde se encuentran componentes relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetar las caras de los dados\n",
    "dado_etiqueta = []\n",
    "cara_dado1 = cv2.connectedComponentsWithStats(\n",
    "    foto[  # Imagen recortada para el primer dado\n",
    "        dados[0][3] : dados[0][3] + dados[0][5], dados[0][2] : dados[0][2] + dados[0][4]\n",
    "    ]\n",
    ")\n",
    "cara_dado2 = cv2.connectedComponentsWithStats(\n",
    "    foto[  # Imagen recortada para el segundo dado\n",
    "        dados[1][3] : dados[1][3] + dados[1][5], dados[1][2] : dados[1][2] + dados[1][4]\n",
    "    ]\n",
    ")\n",
    "\n",
    "imshow(foto,title=\"Dados\")  # Descomentar si deseas ver los dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código realiza la identificación y etiquetado de las caras de los dados, utilizando conectividad conectada para cada dado seleccionado. Las imágenes recortadas se utilizan para procesar cada dado individualmente y obtener las caras visibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar las etiquetas para los dados\n",
    "dado_etiqueta.append(\n",
    "    [\n",
    "        f\"Valor de la cara = {cara_dado1[0]-1}\",\n",
    "        dados[0][2],\n",
    "        dados[0][3],\n",
    "        dados[0][4],\n",
    "        dados[0][5],\n",
    "    ]\n",
    ")\n",
    "dado_etiqueta.append(\n",
    "    [\n",
    "        f\"Valor de la cara = {cara_dado2[0]-1}\",\n",
    "        dados[1][2],\n",
    "        dados[1][3],\n",
    "        dados[1][4],\n",
    "        dados[1][5],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copia = moneda_original.copy()\n",
    "for etiqueta, x, y, ancho, alto in monedas_etiqueta:\n",
    "    # Coordenadas del rectángulo\n",
    "    punto1 = (x, y)  # Esquina superior izquierda\n",
    "    punto2 = (x + ancho, y + alto)  # Esquina inferior derecha\n",
    "\n",
    "    # Dibujar el rectángulo\n",
    "    cv2.rectangle(copia, punto1, punto2, color=(0, 255, 0), thickness=10)\n",
    "\n",
    "    # Añadir la etiqueta (texto)\n",
    "    cv2.putText(copia,etiqueta,(x - 10, y - 10),cv2.FONT_HERSHEY_SIMPLEX,fontScale=2,color=(0, 255, 0),thickness=10,)\n",
    "\n",
    "imshow(copia, title=\"Monedas Etiquetadas\")  # Descomentar si deseas ver las monedas etiquetadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código realiza la visualización de las monedas etiquetadas dibujando rectángulos alrededor de cada moneda en la imagen original. Además, se añade una etiqueta con texto para identificar cada moneda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for etiqueta, x, y, ancho, alto in dado_etiqueta:\n",
    "    # Coordenadas del rectángulo\n",
    "    punto1 = (x, y)  # Esquina superior izquierda\n",
    "    punto2 = (x + ancho, y + alto)  # Esquina inferior derecha\n",
    "\n",
    "    # Dibujar el rectángulo\n",
    "    cv2.rectangle(copia, punto1, punto2, color=(0, 255, 0), thickness=10)\n",
    "\n",
    "    # Añadir la etiqueta (texto)\n",
    "    cv2.putText(copia,etiqueta,(x - 10, y - 10),cv2.FONT_HERSHEY_SIMPLEX,fontScale=2,color=(0, 255, 0),thickness=10,)\n",
    "\n",
    "imshow(copia, title=\"Dados y monedas etiquetados por valor\", blocking=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp-pdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
